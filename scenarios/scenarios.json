{
  "meta": {
    "version": "1.0",
    "project": "cher-llm-simulator",
    "description": "Offizielle Referenzszenarien + Basisbeispiele (v1.0)",
    "defaultScenarioId": "baseline-hund"
  },
  "scenarios": [
    {
      "id": "baseline-hund",
      "title": "Baseline: Was ist ein Hund?",
      "learningGoals": [
        "Grundprinzipien",
        "Tokenisierung",
        "Next-Token-Loop"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Antworte in einem Satz.",
        "user": "Was ist ein Hund?"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Was",
            "id": 1001
          },
          {
            "text": " ist",
            "id": 1002
          },
          {
            "text": " ein",
            "id": 1003
          },
          {
            "text": " Hund",
            "id": 1004
          },
          {
            "text": "?",
            "id": 1005
          }
        ]
      },
      "generation": {
        "outputText": "Ein Hund ist ein Säugetier."
      },
      "highlights": {
        "explain": [
          {
            "at": "tokenizer",
            "text": "Token sind nicht immer identisch mit Wörtern. Häufig werden Subwords bzw. Teilstücke genutzt (z. B. bei Komposita)."
          },
          {
            "at": "decoding",
            "text": "Die Ausgabe entsteht schrittweise: Das Modell wählt jeweils das nächste Token (Next-Token-Prinzip)."
          }
        ],
        "focusByStep": {
          "tokenizer": "Subword-Tokenisierung · Warum Token nicht immer Wörter sind",
          "decoding": "Token-für-Token · Auswahl der nächsten Einheit"
        }
      }
    },
    {
      "id": "kompositum-hundeleine",
      "title": "Komposita: Hundeleine",
      "learningGoals": [
        "Tokenisierung",
        "Subwords",
        "Komposita"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Antworte kurz.",
        "user": "Was ist eine Hundeleine?"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Was",
            "id": 1101
          },
          {
            "text": " ist",
            "id": 1102
          },
          {
            "text": " eine",
            "id": 1103
          },
          {
            "text": " Hund",
            "id": 1104
          },
          {
            "text": "eleine",
            "id": 1105
          },
          {
            "text": "?",
            "id": 1106
          }
        ]
      },
      "generation": {
        "outputText": "Eine Hundeleine ist eine Leine zum Führen eines Hundes."
      },
      "highlights": {
        "tokenFocus": [
          "Hund",
          "eleine"
        ],
        "explain": [
          {
            "at": "tokenizer",
            "text": "Komposita werden in bekannte Teilstücke (Subwords) zerlegt, damit ein endliches Vokabular ausreicht."
          }
        ],
        "focusByStep": {
          "tokenizer": "Komposita zerlegen · Subword-Splitting"
        }
      }
    },
    {
      "id": "posenc-hund-hund-hund",
      "title": "Positionsinformation: Hund Hund Hund",
      "learningGoals": [
        "Embeddings",
        "Positional Encoding",
        "Reihenfolge"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Beobachte die Verarbeitung, nicht die Textantwort.",
        "user": "Hund Hund Hund"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Hund",
            "id": 1201
          },
          {
            "text": " Hund",
            "id": 1202
          },
          {
            "text": " Hund",
            "id": 1203
          }
        ]
      },
      "generation": {
        "outputText": "(Guided) Ausgabe bleibt stabil – beobachte Embeddings & Attention."
      },
      "highlights": {
        "explain": [
          {
            "at": "embeddings",
            "text": "Ohne Positionsinformation wären identische Tokens an allen Stellen gleich. Mit Positional Encoding werden sie unterscheidbar."
          }
        ],
        "focusByStep": {
          "embeddings": "Positional Encoding · Gleiche Tokens werden positionsabhängig"
        }
      }
    },
    {
      "id": "attention-hund-beisst-mann",
      "title": "Kontext: Der Hund beißt den Mann",
      "learningGoals": [
        "Attention",
        "Kontext",
        "MLP/FFN"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Fokus: Attention-Heatmap und MLP-Vergleich.",
        "user": "Der Hund beißt den Mann"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Der",
            "id": 1301
          },
          {
            "text": " Hund",
            "id": 1302
          },
          {
            "text": " beißt",
            "id": 1303
          },
          {
            "text": " den",
            "id": 1304
          },
          {
            "text": " Mann",
            "id": 1305
          }
        ]
      },
      "generation": {
        "outputText": "(Guided) Beobachte Kontextbildung und FFN-Weiterverarbeitung."
      },
      "highlights": {
        "explain": [
          {
            "at": "attention",
            "text": "Attention zeigt, welche Tokens für andere Tokens gerade relevant sind (Kontextgewichtung)."
          },
          {
            "at": "mlp",
            "text": "MLP (FFN) verarbeitet die kontextualisierten Token-Vektoren weiter. Der Vergleich „ohne vs. mit Attention“ macht den Effekt sichtbar."
          }
        ],
        "focusByStep": {
          "attention": "Attention · Kontextgewichtung als Heatmap",
          "mlp": "MLP/FFN · Weiterverarbeitung mit/ohne Kontext"
        }
      }
    },
    {
      "id": "decoding-der-hund-ist-ein",
      "title": "Auswahl: Der Hund ist ein …",
      "learningGoals": [
        "Logits",
        "Decoding",
        "Temperature/Top-K/Top-P/Seed"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Experimentiere mit Decoding-Parametern.",
        "user": "Der Hund ist ein"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Der",
            "id": 1401
          },
          {
            "text": " Hund",
            "id": 1402
          },
          {
            "text": " ist",
            "id": 1403
          },
          {
            "text": " ein",
            "id": 1404
          }
        ]
      },
      "generation": {
        "outputText": "Der Hund ist ein Säugetier."
      },
      "highlights": {
        "explain": [
          {
            "at": "logits",
            "text": "Logits sind Rohwerte: mehrere nächste Tokens können plausibel sein. Noch ist nichts entschieden."
          },
          {
            "at": "decoding",
            "text": "Decoding wählt aus Kandidaten aus. Temperature, Top-K/Top-P und Seed steuern Variation und Reproduzierbarkeit."
          }
        ],
        "focusByStep": {
          "logits": "Logits · Kandidaten-Bewertungen",
          "decoding": "Decoding · Auswahlregeln & Variation"
        }
      }
    },
    {
      "id": "roles-mann-sieht-hund",
      "title": "Reihenfolge: Der Mann sieht den Hund",
      "learningGoals": [
        "Positional Encoding",
        "Attention",
        "Rollen durch Reihenfolge"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Vergleiche mit dem Szenario „Der Hund sieht den Mann“.",
        "user": "Der Mann sieht den Hund"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Der",
            "id": 1501
          },
          {
            "text": " Mann",
            "id": 1502
          },
          {
            "text": " sieht",
            "id": 1503
          },
          {
            "text": " den",
            "id": 1504
          },
          {
            "text": " Hund",
            "id": 1505
          }
        ]
      },
      "generation": {
        "outputText": "(Guided) Vergleiche Embeddings/Attention mit dem invertierten Satz."
      },
      "highlights": {
        "explain": [
          {
            "at": "embeddings",
            "text": "Gleiche Token-Menge, andere Reihenfolge: mit Positional Encoding entstehen andere Eingabe-Vektoren."
          },
          {
            "at": "attention",
            "text": "Die Attention-Muster verändern sich, wenn sich Reihenfolge und damit Beziehungen ändern."
          }
        ],
        "focusByStep": {
          "embeddings": "Positionsinformation · Gleiche Tokens, andere Ordnung",
          "attention": "Attention · Beziehungen kippen mit der Reihenfolge"
        }
      }
    },
    {
      "id": "roles-hund-sieht-mann",
      "title": "Reihenfolge: Der Hund sieht den Mann",
      "learningGoals": [
        "Positional Encoding",
        "Attention",
        "Rollen durch Reihenfolge"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Vergleiche mit dem Szenario „Der Mann sieht den Hund“.",
        "user": "Der Hund sieht den Mann"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Der",
            "id": 1601
          },
          {
            "text": " Hund",
            "id": 1602
          },
          {
            "text": " sieht",
            "id": 1603
          },
          {
            "text": " den",
            "id": 1604
          },
          {
            "text": " Mann",
            "id": 1605
          }
        ]
      },
      "generation": {
        "outputText": "(Guided) Vergleiche Embeddings/Attention mit dem invertierten Satz."
      },
      "highlights": {
        "explain": [
          {
            "at": "embeddings",
            "text": "Gleiche Token-Menge, andere Reihenfolge: mit Positional Encoding entstehen andere Eingabe-Vektoren."
          },
          {
            "at": "attention",
            "text": "Die Attention-Muster verändern sich, wenn sich Reihenfolge und damit Beziehungen ändern."
          }
        ],
        "focusByStep": {
          "embeddings": "Positionsinformation · Gleiche Tokens, andere Ordnung",
          "attention": "Attention · Beziehungen kippen mit der Reihenfolge"
        }
      }
    },
    {
      "id": "limits-bank-geschlossen",
      "title": "Grenzen: Die Bank ist geschlossen",
      "learningGoals": [
        "Mehrdeutigkeit",
        "Kontextgrenzen",
        "Erwartungsmanagement"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Beachte: Mehrdeutigkeit kann ohne Weltwissen bestehen bleiben.",
        "user": "Die Bank ist geschlossen"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Die",
            "id": 1701
          },
          {
            "text": " Bank",
            "id": 1702
          },
          {
            "text": " ist",
            "id": 1703
          },
          {
            "text": " geschlossen",
            "id": 1704
          }
        ]
      },
      "generation": {
        "outputText": "(Guided) Mehrdeutigkeit bleibt möglich – beobachte, was die Pipeline leisten kann und was nicht."
      },
      "highlights": {
        "explain": [
          {
            "at": "attention",
            "text": "Attention gewichtet nur vorhandene Tokens. Sie löst Mehrdeutigkeit nicht automatisch auf, wenn dafür externes Wissen nötig wäre."
          }
        ],
        "focusByStep": {
          "attention": "Grenzen · Kontextgewichtung ist kein Weltwissen"
        }
      }
    }
  ]
}
