{
  "meta": {
    "version": "v1.1",
    "project": "cher-llm-simulator",
    "description": "LLM Simulator – Referenzszenarien v1.1 (kuratiert)",
    "defaultScenarioId": "posenc-hund-hund-hund"
  },
  "scenarios": [
    {
      "id": "posenc-hund-hund-hund",
      "title": "Ref 01 · Positionsinformation — Positionsinformation: Hund Hund Hund",
      "learningGoals": [
        "Embeddings",
        "Positional Encoding",
        "Reihenfolge"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Beobachte die Verarbeitung, nicht die Textantwort.",
        "user": "Hund Hund Hund"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Hund",
            "id": 1201
          },
          {
            "text": " Hund",
            "id": 1201
          },
          {
            "text": " Hund",
            "id": 1201
          }
        ]
      },
      "generation": {
        "outputText": "(Guided) Ausgabe bleibt stabil – beobachte Embeddings & Attention."
      },
      "highlights": {
        "explain": [
          {
            "at": "embedding",
            "text": "Ohne Positionsinformation wären identische Tokens an allen Stellen gleich. Mit Positional Encoding werden sie unterscheidbar."
          }
        ],
        "focusByStep": {
          "embedding": "Positional Encoding · Gleiche Tokens werden positionsabhängig"
        }
      },
      "tags": [
        "referenz"
      ]
    },
    {
      "id": "attention-hund-beisst-mann",
      "title": "Ref 02 · Kontext (Attention/MLP) — Kontext: Der Hund beißt den Mann",
      "learningGoals": [
        "Attention",
        "Kontext",
        "MLP/FFN"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Fokus: Attention-Heatmap und MLP-Vergleich.",
        "user": "Der Hund beißt den Mann"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Der",
            "id": 1301
          },
          {
            "text": " Hund",
            "id": 1302
          },
          {
            "text": " beißt",
            "id": 1303
          },
          {
            "text": " den",
            "id": 1304
          },
          {
            "text": " Mann",
            "id": 1305
          }
        ]
      },
      "generation": {
        "outputText": "(Guided) Beobachte Kontextbildung und FFN-Weiterverarbeitung."
      },
      "highlights": {
        "explain": [
          {
            "at": "attention",
            "text": "Attention zeigt, welche Tokens für andere Tokens gerade relevant sind (Kontextgewichtung)."
          },
          {
            "at": "mlp",
            "text": "MLP (FFN) verarbeitet die kontextualisierten Token-Vektoren weiter. Der Vergleich „ohne vs. mit Attention“ macht den Effekt sichtbar."
          }
        ],
        "focusByStep": {
          "attention": "Attention · Kontextgewichtung als Heatmap",
          "mlp": "MLP/FFN · Weiterverarbeitung mit/ohne Kontext"
        }
      },
      "tags": [
        "referenz"
      ]
    },
    {
      "id": "decoding-der-hund-ist-ein",
      "title": "Ref 03 · Auswahl (Logits/Decoding) — Auswahl: Der Hund ist ein …",
      "learningGoals": [
        "Logits",
        "Decoding",
        "Temperature/Top-K/Top-P/Seed"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Experimentiere mit Decoding-Parametern.",
        "user": "Der Hund ist ein"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Der",
            "id": 1401
          },
          {
            "text": " Hund",
            "id": 1402
          },
          {
            "text": " ist",
            "id": 1403
          },
          {
            "text": " ein",
            "id": 1404
          }
        ]
      },
      "generation": {
        "outputText": "Der Hund ist ein Säugetier."
      },
      "highlights": {
        "explain": [
          {
            "at": "logits",
            "text": "Logits sind Rohwerte: mehrere nächste Tokens können plausibel sein. Noch ist nichts entschieden."
          },
          {
            "at": "decoding",
            "text": "Decoding wählt aus Kandidaten aus. Temperature, Top-K/Top-P und Seed steuern Variation und Reproduzierbarkeit."
          }
        ],
        "focusByStep": {
          "logits": "Logits · Kandidaten-Bewertungen",
          "decoding": "Decoding · Auswahlregeln & Variation"
        }
      },
      "tags": [
        "referenz"
      ]
    },
    {
      "id": "roles-mann-sieht-hund",
      "title": "Ref 04a · Reihenfolge & Rollen — Reihenfolge: Der Mann sieht den Hund",
      "learningGoals": [
        "Positional Encoding",
        "Attention",
        "Rollen durch Reihenfolge"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Vergleiche mit dem Szenario „Der Hund sieht den Mann“.",
        "user": "Der Mann sieht den Hund"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Der",
            "id": 1501
          },
          {
            "text": " Mann",
            "id": 1502
          },
          {
            "text": " sieht",
            "id": 1503
          },
          {
            "text": " den",
            "id": 1504
          },
          {
            "text": " Hund",
            "id": 1505
          }
        ]
      },
      "generation": {
        "outputText": "(Guided) Vergleiche Embeddings/Attention mit dem invertierten Satz."
      },
      "highlights": {
        "explain": [
          {
            "at": "embedding",
            "text": "Gleiche Token-Menge, andere Reihenfolge: mit Positional Encoding entstehen andere Eingabe-Vektoren."
          },
          {
            "at": "attention",
            "text": "Die Attention-Muster verändern sich, wenn sich Reihenfolge und damit Beziehungen ändern."
          }
        ],
        "focusByStep": {
          "embedding": "Positionsinformation · Gleiche Tokens, andere Ordnung",
          "attention": "Attention · Beziehungen kippen mit der Reihenfolge"
        }
      },
      "tags": [
        "referenz"
      ]
    },
    {
      "id": "roles-hund-sieht-mann",
      "title": "Ref 04b · Reihenfolge & Rollen — Reihenfolge: Der Hund sieht den Mann",
      "learningGoals": [
        "Positional Encoding",
        "Attention",
        "Rollen durch Reihenfolge"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Vergleiche mit dem Szenario „Der Mann sieht den Hund“.",
        "user": "Der Hund sieht den Mann"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Der",
            "id": 1501
          },
          {
            "text": " Hund",
            "id": 1505
          },
          {
            "text": " sieht",
            "id": 1503
          },
          {
            "text": " den",
            "id": 1504
          },
          {
            "text": " Mann",
            "id": 1502
          }
        ]
      },
      "generation": {
        "outputText": "(Guided) Vergleiche Embeddings/Attention mit dem invertierten Satz."
      },
      "highlights": {
        "explain": [
          {
            "at": "embedding",
            "text": "Gleiche Token-Menge, andere Reihenfolge: mit Positional Encoding entstehen andere Eingabe-Vektoren."
          },
          {
            "at": "attention",
            "text": "Die Attention-Muster verändern sich, wenn sich Reihenfolge und damit Beziehungen ändern."
          }
        ],
        "focusByStep": {
          "embedding": "Positionsinformation · Gleiche Tokens, andere Ordnung",
          "attention": "Attention · Beziehungen kippen mit der Reihenfolge"
        }
      },
      "tags": [
        "referenz"
      ]
    },
    {
      "id": "limits-bank-geschlossen",
      "title": "Ref 05 · Grenzen & Mehrdeutigkeit — Grenzen: Die Bank ist geschlossen",
      "learningGoals": [
        "Mehrdeutigkeit",
        "Kontextgrenzen",
        "Erwartungsmanagement"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Beachte: Mehrdeutigkeit kann ohne Weltwissen bestehen bleiben.",
        "user": "Die Bank ist geschlossen"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Die",
            "id": 1701
          },
          {
            "text": " Bank",
            "id": 1702
          },
          {
            "text": " ist",
            "id": 1703
          },
          {
            "text": " geschlossen",
            "id": 1704
          }
        ]
      },
      "generation": {
        "outputText": "(Guided) Mehrdeutigkeit bleibt möglich – beobachte, was die Pipeline leisten kann und was nicht."
      },
      "highlights": {
        "explain": [
          {
            "at": "attention",
            "text": "Attention gewichtet nur vorhandene Tokens. Sie löst Mehrdeutigkeit nicht automatisch auf, wenn dafür externes Wissen nötig wäre."
          }
        ],
        "focusByStep": {
          "attention": "Grenzen · Kontextgewichtung ist kein Weltwissen"
        }
      },
      "tags": [
        "referenz"
      ]
    },
    {
      "id": "baseline-hund",
      "title": "Basic · Baseline — Baseline: Was ist ein Hund?",
      "learningGoals": [
        "Grundprinzipien",
        "Tokenisierung",
        "Next-Token-Loop"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Antworte in einem Satz.",
        "user": "Was ist ein Hund?"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Was",
            "id": 1001
          },
          {
            "text": " ist",
            "id": 1002
          },
          {
            "text": " ein",
            "id": 1003
          },
          {
            "text": " Hund",
            "id": 1004
          },
          {
            "text": "?",
            "id": 1005
          }
        ]
      },
      "generation": {
        "outputText": "Ein Hund ist ein Säugetier."
      },
      "highlights": {
        "explain": [
          {
            "at": "tokenization",
            "text": "Token sind nicht immer identisch mit Wörtern. Häufig werden Subwords bzw. Teilstücke genutzt (z. B. bei Komposita)."
          },
          {
            "at": "decoding",
            "text": "Die Ausgabe entsteht schrittweise: Das Modell wählt jeweils das nächste Token (Next-Token-Prinzip)."
          }
        ],
        "focusByStep": {
          "decoding": "Token-für-Token · Auswahl der nächsten Einheit",
          "tokenization": "Subword-Tokenisierung · Warum Token nicht immer Wörter sind"
        }
      },
      "tags": [
        "basic"
      ]
    },
    {
      "id": "kompositum-hundeleine",
      "title": "Basic · Tokenisierung (Komposita) — Komposita: Hundeleine",
      "learningGoals": [
        "Tokenisierung",
        "Subwords",
        "Komposita"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Antworte kurz.",
        "user": "Was ist eine Hundeleine?"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Was",
            "id": 1101
          },
          {
            "text": " ist",
            "id": 1102
          },
          {
            "text": " eine",
            "id": 1103
          },
          {
            "text": " Hund",
            "id": 1104
          },
          {
            "text": "eleine",
            "id": 1105
          },
          {
            "text": "?",
            "id": 1106
          }
        ]
      },
      "generation": {
        "outputText": "Eine Hundeleine ist eine Leine zum Führen eines Hundes."
      },
      "highlights": {
        "tokenFocus": [
          "Hund",
          "eleine"
        ],
        "explain": [
          {
            "at": "tokenization",
            "text": "Komposita werden in bekannte Teilstücke (Subwords) zerlegt, damit ein endliches Vokabular ausreicht."
          }
        ],
        "focusByStep": {
          "tokenization": "Komposita zerlegen · Subword-Splitting"
        }
      },
      "tags": [
        "basic"
      ]
    },
    {
      "id": "embeddings-semantic-clusters",
      "title": "Ref 06 · Embeddings — Semantische Nähe: Zwei Cluster im Raum",
      "learningGoals": [
        "Embeddings",
        "Semantische Nähe",
        "Ähnlichkeit/Distanz",
        "Cluster"
      ],
      "mode": "simulated",
      "promptStack": {
        "system": "Du bist ein sachlicher Assistent.",
        "instruction": "Beobachte die Verarbeitung, nicht die Textantwort.",
        "user": "Mann Mensch Radio Auto"
      },
      "tokenization": {
        "tokens": [
          {
            "text": "Mann",
            "id": 2001
          },
          {
            "text": " Mensch",
            "id": 2002
          },
          {
            "text": " Radio",
            "id": 2003
          },
          {
            "text": " Auto",
            "id": 2004
          }
        ]
      },
      "embeddings": {
        "mode": "groups",
        "groups": {
          "human": [
            "Mann",
            "Mensch"
          ],
          "tech": [
            "Radio",
            "Auto"
          ]
        },
        "params": {
          "jitter": 0.1,
          "groupSeparationHint": "high"
        },
        "notes": "Didaktische Beispiel-Embeddings: Gruppen erzeugen Nähe im Raum (synthetisch, nicht aus einem trainierten Modell)."
      },
      "generation": {
        "outputText": "(Guided) Fokus: Embeddings. Beobachte die Nähe innerhalb der Cluster (human/tech)."
      },
      "highlights": {
        "explain": [
          {
            "at": "embedding",
            "text": "In diesem Szenario werden Embeddings synthetisch so erzeugt, dass Tokens innerhalb eines Clusters (z. B. Mann/Mensch) näher beieinander liegen als Tokens aus verschiedenen Clustern (z. B. Mann/Radio)."
          },
          {
            "at": "embedding",
            "text": "Falls die App eine Ähnlichkeitsanzeige bietet, ist sie nur aktiv, wenn im Szenario ein embeddings-Block vorhanden ist."
          }
        ],
        "focusByStep": {
          "embedding": "Semantische Nähe · Zwei Cluster im Embedding-Raum"
        }
      },
      "tags": [
        "referenz"
      ]
    }
  ]
}
